{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "DGP:\n",
    "\n",
    "* 2 classes; each classes n observations\n",
    "* 2 covariates: $X_1 \\sim \\mathscr{N} (\\mu_1, \\Sigma_1)$ and $X_2 \\sim \\mathscr{N} (\\mu_2, \\Sigma_2)$\n",
    "* $\\mu_1 = (-3, 3)$ for class 1, $\\mu_2 = (5, 5)$ for class 2, $\\Sigma_1=\\Sigma_2=\\Sigma=\n",
    "\\left[ \\begin{array}{ccc}\n",
    "16 & -2\\\\\n",
    "-2 & 9\n",
    "\\end{array} \n",
    "\\right ]$\n",
    "* $n_1=300$, $n_2=500$\n",
    "\n",
    "Use the general procedure for generating the dataframe and for calculating the lda\n",
    "and the qda function from exercise 1 in the last problem set.\n",
    "\n",
    "Questions:\n",
    "\n",
    "**a)** Calculate the mean training error and the mean test error using a new data set with the same specifications\n",
    "as the training data for both methods and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.array([[16, -2], [-2, 9]])\n",
    "\n",
    "# First redefine the functions we have used in the last problem set.\n",
    "def generate_data_ex1(cov1, cov2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n_11 = 300\n",
    "    n_12 = 500\n",
    "    n_21 = 300\n",
    "    n_22 = 500\n",
    "\n",
    "    mu_1 = np.array([-3, 3])\n",
    "    mu_2 = np.array([5, 5])   \n",
    "\n",
    "    y_1 = np.zeros(n_11 + n_12)\n",
    "    y_2 = np.ones(n_21 + n_22)\n",
    "\n",
    "    x_1 = np.random.multivariate_normal(mu_1, cov1, n_11 + n_12)\n",
    "    x_2 = np.random.multivariate_normal(mu_2, cov2, n_21 + n_22)\n",
    "\n",
    "    X = np.concatenate((x_1, x_2), axis=0)\n",
    "    y = np.concatenate((y_1, y_2))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA training mean error: 0.131875\n",
      "QDA training mean error: 0.133125\n"
     ]
    }
   ],
   "source": [
    "# Reconduct the training error analysis for both methods.\n",
    "data_x, data_y = generate_data_ex1(sigma, sigma)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "y_pred_linear = lda.fit(data_x, data_y).predict(data_x)\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "y_pred_quad = qda.fit(data_x, data_y).predict(data_x)\n",
    "\n",
    "lda_mean_error = np.mean(data_y != y_pred_linear)\n",
    "qda_mean_error = np.mean(data_y != y_pred_quad)\n",
    "\n",
    "print('LDA training mean error: {}\\nQDA training mean error: {}'.format(lda_mean_error, qda_mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA mean test error: 0.15\n",
      "QDA mean test error: 0.150625\n"
     ]
    }
   ],
   "source": [
    "# Generate a test dataset.\n",
    "test_x, test_y = generate_data_ex1(sigma, sigma)\n",
    "\n",
    "# Calculate mean test error for both errors.\n",
    "y_tpred_linear = lda.fit(data_x, data_y).predict(test_x)\n",
    "y_tpred_quad = qda.fit(data_x, data_y).predict(test_x)\n",
    "\n",
    "lda_mean_terror = np.mean(test_y != y_tpred_linear)\n",
    "qda_mean_terror = np.mean(test_y != y_tpred_quad)\n",
    "\n",
    "print('LDA mean test error: {}\\nQDA mean test error: {}'.format(lda_mean_terror, qda_mean_terror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Write a function that uses the validation set approach for generating test and training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_set(size, data_X, data_Y, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function designed for validation set approach.\n",
    "    Input:\n",
    "        size (float): A number between ]0, 1[ representing the proportion of spliting.\n",
    "        data_X (np.ndarray): Predictors.\n",
    "        data_Y (np.1darray): Responses.\n",
    "        **kwargs:\n",
    "            random_states (int): The seed used by the random number generator. Default 1.\n",
    "            method: Estimation method. In this situation default is \n",
    "                    LinearDiscriminantAnalysis(solver='svd')\n",
    "    Output:\n",
    "        train_X, train_Y, test_X, test_Y (np.ndarray): Training sample and test sample.\n",
    "        z(np.1darray): Array of mean error rate.\n",
    "    \"\"\"\n",
    "    random_states = kwargs.get('random_states', 1)\n",
    "    method = kwargs.get('method', LinearDiscriminantAnalysis(solver='svd'))\n",
    "    \n",
    "    # Set random states.\n",
    "    r_state = np.arange(0, random_states)    \n",
    "    \n",
    "    # Generate 10 random splits of the dataset and do the LDA fit.    \n",
    "    z=[]\n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    test_X = []\n",
    "    test_Y = []\n",
    "    for r in r_state:\n",
    "        #poly = PolynomialFeatures(x[i, j])\n",
    "        #x_poly = poly.fit_transform(data_X)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            data_X, data_Y, test_size=size,\n",
    "            random_state = r\n",
    "        )  # The way of setting the random_state is to gurantee that \n",
    "           # we have 10 times different random draws.\n",
    "        train_X.append(x_train)\n",
    "        train_Y.append(y_train)\n",
    "        test_X.append(x_test)\n",
    "        test_Y.append(y_test)\n",
    "\n",
    "        # Test error rate.\n",
    "        y_pred = method.fit(x_train, y_train).predict(x_test)\n",
    "        z.append(np.mean(y_pred != y_test))\n",
    "        #z.append(1 - accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    z = np.array(z)\n",
    "    train_X = np.array(train_X)\n",
    "    train_Y = np.array(train_Y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_Y = np.array(test_Y)\n",
    "        \n",
    "    return train_X, train_Y, test_X, test_Y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look on the validation_set result.\n",
    "tnx, tny, ttx, tty, err = validation_set(0.5, data_x, data_y)\n",
    "err.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Actually the error rate of validation set approach should be one single float. However, considering the very unstable property of this method, you can repeat the split for $m$ different times  by setting `random_states=m` and calculate the mean value of those errors. Here by default, `random_states=1` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Write a function that performs k-fold cross-validation for generating test and training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(folds, data_X, data_Y, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function designed for validation set approach.\n",
    "    Input:\n",
    "        folds (int): How many folds for spliting data?\n",
    "        data_X (np.ndarray): Predictors.\n",
    "        data_Y (np.1darray): Responses.\n",
    "        **kwargs:\n",
    "            random_states (int): The seed used by the random number generator. Default 1.\n",
    "            method: Estimation method. In this situation default is \n",
    "                    LinearDiscriminantAnalysis(solver='svd')\n",
    "            score_method: How to evaluate the mean error rate: for this classification\n",
    "                        situation, default is set to accuracy_score.\n",
    "    Output:\n",
    "        train_X_r, train_Y_r, test_X_r, test_Y_r (np.ndarray): 4d array;training sample and test sample.\n",
    "        z(np.1darray): Array of mean error rate.\n",
    "    \"\"\"\n",
    "    random_states = kwargs.get('random_states', 1)\n",
    "    method = kwargs.get('method', LinearDiscriminantAnalysis(solver='svd'))\n",
    "    #score_method = kwargs.get('score_method', accuracy_score)\n",
    "    # Set random states.\n",
    "    r_state = np.arange(0, random_states)    \n",
    "    \n",
    "    # Generate folds random splits of the dataset for r_state times and do the LDA fit.    \n",
    "    k_err=[]\n",
    "    train_X_r = []\n",
    "    train_Y_r = []\n",
    "    test_X_r = []\n",
    "    test_Y_r = []\n",
    "    for r in r_state:\n",
    "        z=[]\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "        test_X = []\n",
    "        test_Y = []\n",
    "        kf = KFold(n_splits=folds, random_state=r, shuffle=True)\n",
    "        for train_index, test_index in kf.split(data_X):\n",
    "            x_train, x_test = data_X[train_index], data_X[test_index]\n",
    "            y_train, y_test = data_Y[train_index], data_Y[test_index]           \n",
    "            \n",
    "            # Appending to the list.\n",
    "            train_X.append(x_train)\n",
    "            train_Y.append(y_train)\n",
    "            test_X.append(x_test)\n",
    "            test_Y.append(y_test)\n",
    "            \n",
    "            # Test error rate.\n",
    "            y_pred = method.fit(x_train, y_train).predict(x_test)\n",
    "            z.append(np.mean(y_pred != y_test))\n",
    "        \n",
    "        \n",
    "        z = np.array(z)\n",
    "        train_X = np.array(train_X)\n",
    "        train_Y = np.array(train_Y)\n",
    "        test_X = np.array(test_X)\n",
    "        test_Y = np.array(test_Y)\n",
    "    \n",
    "    k_err.append(z)\n",
    "    train_X_r.append(train_X)\n",
    "    train_Y_r.append(train_Y)\n",
    "    test_X_r.append(test_X)\n",
    "    test_Y_r.append(test_Y)\n",
    "    \n",
    "    k_err = np.array(k_err)\n",
    "    train_X_r = np.array(train_X_r)\n",
    "    train_Y_r = np.array(train_Y_r)\n",
    "    test_X_r = np.array(test_X_r)\n",
    "    test_Y_r = np.array(test_Y_r)    \n",
    "    \n",
    "        \n",
    "    return train_X_r, train_Y_r, test_X_r, test_Y_r, k_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11875, 0.18125, 0.125  , 0.18125, 0.13125, 0.11875, 0.11875,\n",
       "        0.08125, 0.175  , 0.09375]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look on k_fold function's results (an array with k mean errors).\n",
    "kf_tnx, kf_tny, kf_ttx, kf_tty, kf_err = k_fold(10, data_x, data_y)\n",
    "kf_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Evaluate the difference between the lda and qda methods through calculating classification training and test\n",
    "error for 100 different simulation runs. For each run, compare the difference between the\n",
    "\n",
    "**a)** validation set approach\n",
    "\n",
    "**b)** 5-fold cross-validation\n",
    "\n",
    "**c)** 10-fold cross-validation\n",
    "\n",
    "From the theoretical properties discussed in the lecture, propose a suitable metric for comparing these three\n",
    "methods and compare the results of your simulation study with your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparisions In Test Errors Among Different Methods')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB4AAADZCAYAAACHBPMsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZhcZZX48W8nAcKOzaowiAocBGNwQAGHVVlCBJeZQRlQIiMqqEQFBxllfuqMioooBAcdWQQHEBgVRQwhzAAuRED2AOaYRgMDGgSasExISNL9++O9TSpFdzrb7apOvp/nyZO6+6mq21X1nnve93b09vYiSZIkSZJUhxGtDkCSJEmSJK2+TDxIkiRJkqTamHiQJEmSJEm1MfEgSZIkSZJqY+JBkiRJkiTVxsSDJEmSJEmqzahWByBJGt4iYiTwceAoyvfK2sDPgP+XmfNbGVujiDgfuDwz/3uA5a8AfpiZb645js8Dm2Xmx5Zx/U2Am6rJDYCtgaymr8/Mf1qBGPYEjsnMj/Sz7BLgAODxpkXnZea/L++xVpWIOBs4HtguM//cqjj6ExFfBD4MPFrNWgu4m/I38GD1N3IHsA/wPPATYAfgLOAF4HPA9Mx8W81xvgY4PTPf3c+yS4CjgX0z81cN87cHZgJnZ+YnBtn/F4DfZuY11f5uz8yzViLeU4HtM/O4Fd2HJKk9mHiQJK2sbwMvA96amU9HxPrApcD5wPtaGlmDwRovmfknoNakw4rIzDnArgARsT/wrczcdSV3+zrgFUtZfsbKNBhXtYhYD3gv8GPgo8BprY2oX5c2Nswj4ljgxojYOTOfY/F7+GpKYmfDzOyJiF8Cp2Tm5UMQ46uAHZey/GHK3+yvGuYdAzy2jPt/K3DXioUmSVqdmXiQJK2wiNiOcpX05Zn5DEBm/l9EHA/8TbXOxsC/UxpevcC1wGcyc2FEzAO+ARxIuZr/eeAIYAzwJ+Dwan8Lga8AhwLrV9v/uEpyfJty9XhT4FngqMzMiLgJ6AZ2qtb5O+BblKvN51TxLQD+ABwLbAbcl5kbRMRaVVxvBRYBtwKfzMxnI2IWcFG1bFvg+5n5LxGxAfC9KpYeyhXuD2dmz1Jev4uAZ6rn+1fAvZRKhOeW9T2o9vMhyhX3EZRKhY9l5u8jYj/g60BHteoXqa7EAxtHxPnLezU5Ih4Bfg2MBU6hvLaN07Mor28n5f3+WmZeGhEHAmcA84B1gf2AC4HXUF6v24ATMrO3n8MeBfwOOBv4WUR8KTOfb4jnYsr7sQnwVWBfYLfqWG/PzNkRMWYpcX0OeAjYhfLb6EOZ+ZuI2JLynm4HPFm9tndm5hcHe50y83sR8T7gyOp9XkBJ0F0DjAbujIiHgb8GTo+ILYD/AL5GqYzoq5L4eHXeNb/ud1PO520oFRaXZuZXqwqFycB/A2+sXpOTgSnAd4CtI2JyZo7vJ+wfAB+IiBMzc35EdFD+Hn/Yt0JEvKx6H3apjnt9Fc9HKX/j34yIvnN+n4h4N7Al5dw+OjPnVufl16rX4QXgs5k5NSLWrt6jtwJ/qf49UR33COAzwELK3+TJmXnzYO+DJKk9OMaDJGll7Abc35d06JOZszPzR9XkJEqjbQywO6Xh9Klq2TrA7Mx8E6XxeD7wCWBnYGPgHdV6I4G5mbkb8G7gwojYnJKImJOZe2XmjsBvgcYuDE9l5s6ZeU7DvL2A/YGx1f7+ALy+6XmdRqkIGFv9G0FpNPfZIDP3oVRIfCoiXgW8i3IVe1dKgw/g1QO+covtBowDXktp4B6xDNu8KCLeAvwDsHdmvoFSvt/XUPxX4KuZuTvwQeAtmTmrmn/jUpIO/xQRdzf927lh+T2Z+drM/FnjNKVxezXwjcx8PfA24IyIeFO13hjgiOo1+ltgnerxmyiN2O0GiOcE4JLMvIWSTHpv0/K1MnNP4N+A84Azq+M/BhxTJZKWFtee1ev0BuASSoIGSsP+rszcGTiS5a+Iuad6zo3eDjybmbtm5tspCYRPZuYk4LOUrhi7ZeZYSqP7S437a3jdLwW+U53DewDjI+Jvq/V2AK7OzDdSzuVvZuYLlK4qOUDSAWA2cDtwWDW9X/Uc5jSsczbwm+q4bwBeTkmOTGp4LldX676ckkQISrXFO6q/2yuBj1bP8R+ByyJiW+DEar3XAgez5PnwdeCD1XP6QhWbJGmYMPEgSVoZPQz+XXIopXtAbzXmw3eqeX36EhQPUvq5P1pVCfyRcnW6z7cAMvNeYDqlL/oPgYsi4sRqDID9KZUTfRpLxvtMp6piiIh/A36UmdP6ifk7mbmgiuWcpph/WsXyKOWqbCflavQuVaXFqcBZmdm19JcGgCmZOT8zF1SxdQ62QZPDKA2730TE3cCXgc2rSpMrge9U/e3HsuxdFM6oGsaN/x5oWN78uvZNvxYY0dfwzMxHgKuAQ6rls6p5AL8Edo2IGyhXzL+emX9sDiQi9qBcXb+imnUxZUyRRo3n0KOZeV/DdOcyxPWHzJxePb6Txe/BeOC71TaPUrp6LI9eYO5yrH8YJSFzV/VeHkZJwvX5FUBEbESp2Dm9Wu83lLE/+rrgzAeu6+f5LIvvszixM4FS3dPobcBHq+PeQUmcNSdX+lyVmc9n5kLgfmALSuJvRmbeDlC97rdSEgkHUio3FlRVP5c17OtySrXLecCGwJnL8ZwkSS1m4kGStDJuBV4bERs2zoyIrSPi5xGxLuW7prF8fgTl6nafxgEoFyzlWAub9rEoIk4ALqA07i6jlIp3NKz3ki4L1ZgJfVUXi4ArIqJ5kMWRg8T8fMPjXqCjajRvD5wObAT8d0QcvpTnM+C+lmGb5li/15cgoDQE35iZT2cZDHIs8D+UxMk9VTn7ymp+Xfumm183WPK1e3G7zHyQ8np9jdId4IaI6O9K/Eco79NdVTeXjwA7R8TBDesMdg4NFtdA78FClnw/FvWz76V5IyWZtKxGUioB+t7LPYD3NCxvfJ0B9mhYdy9KNxOAeQ1dVpb3nPoJsHdE/FW1z+ublo8C3tVw3D0pVUr9aXwv+uIY7L1ojPXFv/nM/DSlC8qdlCqJG5f1CUmSWs/EgyRphWUZkPFSSteHjeDFq7HnAk9W/fCvAz4WER0RsQ7wIV7amFkWx1T7/2vKuA2/oFyxvigzL6Dc6eFwFjfK+hURh1Ea4tMy8/OUK7xvbFptCnBCRKwVESMo/deXGnOVBPkeMLVqJF1H6b9ft+uAo6vxCKDEOrWK6TbgdZn5PcrrvjnlqvNClkykrCoPACMi4u3V8behdEF5yZ1EIuJESjXBdZl5CuU9eUPTOp2UrjXjMnO76t82lKvfS73DworG1eTnwAeqbTajdP3pbwyK5ufWUY27sQ2LqzGWxXXAidV5N5IyBsZLxpPIzKco1QafrI73MkrVw2HN6zYZ9H2v/mavpvxd/CQzm5Mt1wGfrJ7jaMqYFccv6/6BacDrImL3KvYxlOqNmyjjvxwTEetUSct3V+usFREPUbrUfJvSJWPXiHCsMkkaJkw8SJJW1kcoDbtpVfn1rdV03/gBEymN3enVv2TJfuvL6m8i4k5KY+w9VePr68CHI+JeShn6nZSr6EtzLaXs+76IuJ3Sb/8LTet8kdLf/W7KoIZr8dLy/mbfpyQ9HoiIOyhjVExaxue2wjJzMmUgzP+JiOnA31MG0oRS1XF6RNxFuUL82aqbwTQgIuK/Bthtf2M8DHorzaorzTso417cS2mk/ktm/rKf1S+iDDJ5f/V6rUsZhLTRscDd2XB7x8q/AQdHxE6DxbQCcTWaCIypXtcrKQNQDtR14ujqdbqLct68Fdg/l++Wsp8HHqm2v59SMTDQ7VKPBPatns8twMWZecUA6/a5D+iJiN8Mst73Kd2WLupn2Ucpg2ROp4z/cCeLuz1cTRk7o3kMjhdl5mOUKo5vV6/rfwLvy8w/UBKW91Ke+02U8VeouiGdBFxZfQb8ADi26sIhSRoGOnp7B03cS5LUUhHRC2yemU+0OhatOSLiY8BvM/PW6ur+zcCpmbkiFTuSJK2xLFGTJEnq3wPAuVV3m7WBK0w6SJK0/Kx4kCRJkiRJtXGMB0mSJEmSVBsTD5IkSZIkqTbDZoyH6hZsbwT+zPLfR1uSJEmSJNVnJPByysDMS9zVadgkHihJh+bbaUmSJEmSpPaxD/Drxhm1JB6q0Z/PBcYC84HjMrOraZ3NKfcRH5OZ8yJiJOU+5LsD6wCfz8xrGjb5M8Cll17KVlttVUfYkiRJkiRpBcyePZujjz4aqrZ7o7oqHt4JjM7MvSJiT+BM4B19CyPiEOArwJYN27wPWCsz/yYitgaOaNrnIoCtttqKbbbZpqawJUmSJEnSSnjJ0Ah1DS65NzAFIDNvoVQxNOoBDgS6G+YdAjwSET8HzgN+VlNskiRJkiRpiNSVeNgIeLphelFEvFhdkZnXZ+aTTdtsBuwAHAZ8FfheTbFJkiRJkqQhUlfi4Rlgw8bjZObCQbZ5ErgmM3sz8xfAjjXFJkmSJEmShkhdiYebgfEA1RgP05dhm183bDMWeLim2CRJkiRJ0hCpa3DJq4CDImIa0AEcGxEnAV2ZefUA25wHfDsibqm2Ob6m2FpqypQpTJ48udVh0N1dhtfo7OxsaRzjx49n3LhxLY1BkiRJklSfWhIPmdnDSxMHM/pZb7uGx/OBf6wjHr3Uk0+WITZanXiQJEmSJK3e6qp40ADGjRvXFlf4J06cCMCkSZNaHIkkSZIkaXVW1xgPkiRJkiRJJh4kSZIkSVJ9TDxIkiRJkqTaOMaDpBe1w11X2uWOK+BdVyRJkqRVwcSDpLbiHVckSZKk1YuJB0kvaoe7rnjHFUmSJGn14hgPkiRJkiSpNiYeJEmSJElSbUw8SJIkSarNE088wYknnvjiOE5Su/DcHDomHiRJkiTV5uKLL+bee+/l4osvbnUo0hI8N4eOiQdJkiRJtXjiiSe49tpr6e3t5dprr/XKstqG5+bQMvEgSZI0zFkurHZ18cUX09vbC0BPT49XltU2PDeHlokHSZKkYc5yYbWr66+/ngULFgCwYMECpk6d2uKIpMJzc2iZeJAkSRrGLBdWOzvooINYa621AFhrrbU4+OCDWxyRVHhuDi0TD5IkLSPL2dWOLBdWO5swYQIdHR0AjBgxggkTJrQ4Iqnw3BxaJh4kSVpGlrOrHVkurHa22Wabceihh9LR0cGhhx7Kpptu2uqQJMBzc6iNqmOnETECOBcYC8wHjsvMrqZ1NgemAWMyc15EdACPADOrVX6Tmf9cR3ySJC2v5nL2CRMm+CNFbeGggw5i8uTJLFiwwHJhtaUJEyYwa9Ysryir7XhuDp26Kh7eCYzOzL2AU4EzGxdGxCHAVGDLhtmvAe7MzP2rfyYdJEltw3J2tSvLhdXuNttsM8455xyTtWo7nptDp67Ew97AFIDMvAXYvWl5D3Ag0N0wbzdg64i4MSImR0TUFJskScvNcna1K8uFJUntrq7Ew0bA0w3TiyLixW4dmXl9ZjaPzPVn4PTMPAD4MnBJTbFJkrTcHP1a7WzChAm8/vWvt9pBktSW6ko8PANs2HiczFw4yDa3Az8FyMxfU6ofOmqKT5Kk5WI5u9qZ5cKSpHZWV+LhZmA8QETsCUxfhm0+B3yi2mYs8HBm9tYUnyRJy8VydkmSpBVTy10tgKuAgyJiGtABHBsRJwFdmXn1ANt8BbgkIt4GLATeX1NskiStEEe/liRJWn61JB4yswc4vmn2jH7W267h8VPA2+qIR5KkVaGvnF2ShoMpU6YwefLkVodBd3cZT76zs7OlcYwfP55x48a1NAZpTVVXxYMkSZIk8eSTZUz5ViceJLWOiQdJkiRpNTRu3Li2uMI/ceJEACZNmtTiSCS1Sl2DS0qSJEmSJFnxIElqf/ZTXpL9lCVJ0nBi4kGSpGVkP2VJkqTlZ+JBktT27KcsSZI0fDnGgyRJkiRJqo0VD5IkSSuhHcYgaZfxR8AxSCQNrh0+N6F9PjvXhM9NEw+SJEnDnOOPSNLy87Nz6Jh4kCRJWgntMAaJ449IGk7a4XMT/OwcSo7xIEmSJEmSamPiQZIkSZIk1cbEgyRJkiRJqo2JB0mSJEmSVBsTD5IkSZIkqTYmHiRJkiRJUm1MPEiSJEmSpNqMqmOnETECOBcYC8wHjsvMrqZ1NgemAWMyc17D/J2AW4EtG+dLkiRJkqThp66Kh3cCozNzL+BU4MzGhRFxCDAV2LJp/kbVuvNrikuSJEmSJA2huhIPewNTADLzFmD3puU9wIFAd9+MiOgAvgt8BphbU1ySJEmSJGkI1dLVAtgIeLphelFEjMrMhQCZeT1ARDRu8zng55l5T9N8abU3adIkurq6Bl9xDTBz5kwAJk6c2OJI2sP222/vayFJkqRhra7EwzPAhg3TI/qSDkvxXuCRiPgAsBWlK8a+NcUntZWuri5+f9+dbLvBolaH0nIb9XYAMG/Wb1scSes9/NzIVocgSZIkrbS6Eg83A4cDV0bEnsD0wTbIzO37HkfELODgmmKT2tK2GyzitN2fa3UYaiNfvH2DVocgSZIkrbS6Eg9XAQdFxDSgAzg2Ik4CujLz6pqOOSjL2ReznH1JlrNLkiRJUj1qSTxkZg9wfNPsGf2st90A2/c7f2V1dXVx1/QH6Fmvs47dDysdi8pbf8eDs1scSeuNmNs9+EqSJEmSpBVSV8VD2+pZr5N5Ox/W6jDURkY/cE2rQ5AkSZKk1VZdt9OUJEmSJEky8SBJkiRJkupj4kGSJEmSJNXGxIMkSZIkSaqNiQdJkiRJklQbEw+SJEmSJKk2Jh4kSZIkSVJtRrU6AEmSJGl1M2nSJLq6ulodRluYOXMmABMnTmxxJK23/fbb+zpojWTiQZK0VP54Xswfz0tq9Q9oz83FPDeX1OpzE6Crq4v7p/+OTdbboqVxtIMRi9YB4NEHn2xxJK01Z+5fWh0C4GdnIz87l1TnZ6eJB0nSUnV1dXHX/XfBJq2OpA1UHRTvevSu1sbRDua0OoBybs64+262anUgbWDd6v85d9/d0jjawexWB9Bgk/W24ICdjmx1GGoTN864vNUhAOWz87577mHDtW0K9i7qAeCh393f4kha79kXFta6f882SdLgNoGe/XtaHYXayIib2mOYqK2AD9DR6jDURi6gt9UhSG1vw7VH8aYtX9bqMNRGbnvsqVr3b+JBagPd3d08/uxIvnj7Bq0ORW3koWdHsnl3d6vDkCRJklZKe1yukCRJkiRJq6UVqniIiHUyc/6qDqZu3d3djJj7JKMfuKbVoaiNjJj7JN3da7c0hs7OTtZ75kFO2/25lsah9vLF2zdgdGdnq8OQJEmSVspSKx4i4oqGxyc3LLq2togkSZIkSdJqY7CKh8b7/7wNOLN6PCxHcers7OSPT73AvJ0Pa3UoaiOjH7iGTq8qS5IkSVItlmeMh8Zkg8MFS5IkSZKkQQ1W8dA7wOOliogRwLnAWGA+cFxmdjWtszkwDRiTmfMiYn3gMqAT+D/gfZn5+LIeU5IkSZIktZ/BKh52iYjLIuIHTY93HmS7dwKjM3Mv4FQWd9EAICIOAaYCWzbM/iBwR2buA1wOnLYcz0OSJEmSJLWhwSoe3t3w+DsDPO7P3sAUgMy8JSJ2b1reAxwI3NE3IzPPioiR1eS2wGODHEOSNAS6u7thDoy4yTswq8Ec6F63u6UhdHd38xhwgT1A1eDPQE93a89NqZ11d3fz7AsLue2xp1oditrIsy8sLL/5arLUxENm/iIixmbmPRGxNqUqYT5w4SD73Qh4umF6UUSMysyF1X6vB4iI5uMtiogbgDHAQcv1TCRJkqQ20d3dzZy5f+HGGZe3OhS1iTlz/8K63cNyjH5ppS018RARJwHviYi/Ac4AXgk8BHwT+PhSNn0G2LBhekRf0mEwmfmWiNgJ+DnwmmXZRpJUn87OTh56/iF69u9pdShqIyNuGtHyOwJ1dnYy4uGH+cDwvNmWanIBvWzi3aqkAXV2dvLsY3/mTVu+rNWhqI3c9thTtX6vD9bV4lDgzZSBJY8CdszMpyJi2iDb3QwcDlwZEXsC0wcLJCL+GXgkM/+TMrjkosG2kSRJktpRZ2cnzz/VywE7HdnqUNQmbpxxecsTtlKrDNZhtyczFwG7An/IzL6OQINdWrgKmFclKL4JfDIiToqIty9lmwuBoyPiJsrdLY4dNHpJkiRJktTWBqt4ICJ2pCQBflZN78Ig1QiZ2QMc3zR7Rj/rbdfw+DFg3KARS5IkSZKkYWOwiofTgP8EtgDOioj9gGuBT9UdmCRJkiRJGv4Gq3g4Abif0rViErAu8CvgQ8At9YYmSZIkSZKGu8ESD7tTkg2XAtMYfGwHSZIkSZKkFy21q0Vmvh54FzAaOBXYC3gwM68bgtgkSZIkSdIwN+jgkpl5HyXpQETsC5weEX+VmXvWHZwkSZIkSRreBk08AETERpTKh38A1gcuqTMoSZIkSVI9nn1hIbc99lSrw2i5+Yt6AFhn5GD3XFj9PfvCwlr3v9TEQ0QcQUk2bAv8GDg+M2fVGpEkSdIymg1cQG+rw2i556r/N2hpFO1hNrBJq4OQ2tj222/f6hDaxsyZMwF45Q47tDiS9lDnuTFYxcMVwAzgHmAM8OWIACAzj6otKkmSpEH443mxx6sfz9v445lNaJ9zY87cv3DjjMtbHUbLzVvwfwCMXmv9FkfSWnPm/oWt2bTVYTBx4sRWh9A2+l6LSZMmtTiS1d9giYcDhiQKSZKk5eSP58X88dx+2iX50Q5mzuwGYOvXbNviSFprazb1vNAaa6mJh8z8xVAFIklqY3NgxE32f2Re9f/olkbRHuYAW7c6CKl9mRhbzMSYpGUaXFJS/R5+biRfvN3euU+/0AHAxmvbZ/vh50ayY6uDwKt2jfr6gu6wteXsbO25IUmSlo2JB6kN+ON9sf+tGnZbbmfDbkfa49zwqt1iXrWTJElafiYepDZgw24xG3aSJEnS6mWNSzyMmNvN6AeuaXUYLdex4HkAetdat8WRtN6Iud3AVq0OQ5IkSZJWS2tU4qEdSpbbxYv9lF9jgxu28tyQJEmSpJqsUYkHy9kXs5xdkiRJkjQUvDeaJEmSJEmqTS0VDxExAjgXGAvMB47LzK6mdTYHpgFjMnNeRGwMXAJsBKwNnJSZv6kjPkmSJEmSNDTqqnh4JzA6M/cCTgXObFwYEYcAU4EtG2afBPxPZu4HvB/495pikyRJkiRJQ6SuxMPewBSAzLwF2L1peQ9wINDdMO+bwH9Uj0cB82qKTZIkSZIkDZG6BpfcCHi6YXpRRIzKzIUAmXk9QES8uEJmzqnmbUXpcvGJmmKTJEmSJElDpK6Kh2eADRuP05d0WJqIGAP8D/CZzPxFTbFJkiRJkqQhUlfi4WZgPEBE7AlMH2yDiNgZ+C/gqMy8tqa4JEmSJEnSEKqrq8VVwEERMQ3oAI6NiJOArsy8eoBtTgdGA2dXXTCezsx31BSfJEmSJEkaArUkHjKzBzi+afaMftbbruGxSQZJkiRJklYzdXW1kCRJkiRJMvEgSZIkSZLqY+JBkiRJkiTVxsSDJEmSJEmqjYkHSZIkSZJUGxMPkiRJkiSpNiYeJEmSJElSbUa1OgBJkgYzZcoUJk+e3OowmDlzJgATJ05saRzjx49n3LhxLY1BkiRpWZl4kCRpGW266aatDkGSJGnYMfEgSWp748aN8wq/2lY7VOS0SzUOWJEjSXopEw+SJEnDnNU4kqR2ZuJBkiRpJViRI0nS0pl4kCRJkiQNmXboogbt001tTeiiZuJBkiRJkrTGsZva0DHxIEmSJEkaMnZRW/OYeJAkSZJWQ5azL2lNKGeX2pWJB0mSJEm1sZxdUi2Jh4gYAZwLjAXmA8dlZlfTOpsD04AxmTmvYf67gCMy86g6YpMkSZLWBJazS2oXI2ra7zuB0Zm5F3AqcGbjwog4BJgKbNk0/2zg9BrjkiRJkiRJQ6iuBv7ewBSAzLwF2L1peQ9wINDdNH8acEJNMUmSJEmSpCFWV+JhI+DphulFEfFit47MvD4zn2zeKDOvAHprikmSJEmSJA2xuhIPzwAbNh4nMxfWdCxJkiRJktSm6ko83AyMB4iIPYHpNR1HkiRJkiS1sbpup3kVcFBETAM6gGMj4iSgKzOvrumYkiRJkiSpzdSSeMjMHuD4ptkz+llvu37m3QTcVEdckiRJkiRpaHnbSkmSJEmSVBsTD5IkSZIkqTYmHiRJkiRJUm1MPEiSJEmSpNqYeJAkSZIkSbUx8SBJkiRJkmpj4kGSJEmSJNXGxIMkSZIkSaqNiQdJkiRJklQbEw+SJEmSJKk2Jh4kSZIkSVJtTDxIkiRJkqTamHiQJEmSJEm1MfEgSZIkSZJqY+JBkiRJkiTVxsSDJEmSJEmqjYkHSZIkSZJUm1F17DQiRgDnAmOB+cBxmdnVtM7mwDRgTGbOi4h1gUuALYBngQmZ+Xgd8bXSlClTmDx5cqvDYObMmQBMnDixpXGMHz+ecePGtTQGSZIkSVJ96qp4eCcwOjP3Ak4FzmxcGBGHAFOBLRtmnwBMz8x9gO8Dp9UUm4BNN92UTTfdtNVhSJIkSZJWc7VUPAB7A1MAMvOWiNi9aXkPcCBwR9M2X6seXwv8S02xtdS4ceO8wi9JkiRJWmPUlXjYCHi6YXpRRIzKzIUAmXk9QEQMtM2zwMY1xSZpAO3QFahdugGBXYEkSZKkVaGuxMMzwIYN0yP6kg7LuM2GwJw6ApPU3uwCJEmSJK1e6ko83AwcDlwZEXsC05dxm/HAbcChwK9qik3SAOwKJEmSJGlVqyvxcBVwUERMAzqAYyPiJKArM68eYJtvAxdHxK+BF4CjaopNkiRJkiQNkVoSD5nZAxzfNHtGP+tt1/B4LnBEHfFIkiRJkqTWqOt2mpIkSZIkSSYeJEmSJElSfeoa46EOIwFmz57d6jgkSZIkSVKDhrb6yOZlwynx8HKAo48+utVxSJIkSZKk/r0ceLBxxnBKPPwW2Af4M7CoxbFIkiRJkqTFRlKSDr9tXtDR29s79OFIkiRJkqQ1goNLSpIkSZKk2gynrhaS2lhE/BL4fGbe0DDvbMIaHAUAAAs4SURBVOARYE9gA6ADeAiYmJnP97OPicDRwDygF/hqZl5bLXsBmFatui5wXXW8nmr5K4AuYEJm/lctT1KSJEnScjPxMMysisZdtc37gZ0y89Sm+bOAh4EeYDRwB3ByZs6rlo8GZgFnZuYZq/Cpafj7LnAMcANARKwNHA78CLg+M79TzT8LOB74ZuPGEXEisAewb2bOj4hNgckR8VRm3gJ0Z+b+1bodwHeAjwLnVLs4Fji7mmfiYQ0WEXcBT1eTf6R8Jv410N2w2jGZ+XA/224HXJ6ZezbN/wowIzMvGuCYnwdm953nDfNNmAlozXlZrXMU5XNxEaXS9buZ+f1q2Sz8zl/jRcQelET//hGxPXARJfl/H/DRzOxp+iwDeCAzPzLA/j5P/5+HszNzq6XEMYvy23Rew7z3A/8K/IFy/vYCX2j6Hfxp4BPAqxq31fDWRuflBsDplN+ozwPPUD4nfx8R+wNXAg9QPtPXAs7KzCsbtn8PcCGwQ2b+aTlegtWOXS2Gn77GHbBE424LSuPukMw8GPg/SuNuRRycmftXP3D+BHypYdnfAZcD748Izx81+iFwQESsV02/A5hK+dH69xFxYESsC3wKmNTP9h8DPp6Z8wEy80ngc8AJzStmZi9wJvAeeDER8T7gG8DaEfG6Vfi8NIxUDSWqz7D9M/PYatEpDfP2769xV5PuvmNSksNbUhqBfRoTZlpNteq8jIjDgQ8A4zNzX+Ag4D0RcUTDan7nr8Ei4hTgfEriCcr36GmZuQ+lIfWOan5307nab+OuJpdVx9wXeDfw7YhobCgeTTlPjxzCmFSjNjsvLwYyM9+UmfsBpwE/iYiNq+U3VMfeDzgY+HRE7Nqw/XGUi2QfqiG2YcWKh+Hnh8CXImK9zJzLSxt3XcDNlMbdqhg59BvA74CTq+njKFnlLYDxwDWr4BhaDWTmvIj4KfAu4FJKg+o04G5KhvifKJUIvwY+Avxv0y5elplPNM2bBWw3wCEfAzarHr8VmJ6Zj0fEhZRG3EsSFlojjAXWi4iplO+4zwy0YkS8gfJjYBGle88Hm5b/HeUcfhxYG5ixMoFlZm9EnEm58nFOQ8JsH+CnEfG6zLxvZY6httWq8/JESnLjaYDMfD4iTgb+g/4rw/zOX/M8CPwt8J/V9G7AL6rH11IaUlcNtHF1Ph0JLAR+mZmfblg2knLBbJfqOOusbLCZ+VhE/Ag4DDi/uuL8IKUK8hLKVXENf21xXlZViTtk5t/1zcvMeyLi6iq+Pzaun5nPRcR/AH8P3B0RrwI6KRUTd0bElzJzweBPf/Vk9nqYqUrI+hp3UBp33wW+DVxGadz9ifLH+IpVcLznqbKNEbEDsH5m3kP54ewVOjU7D3hf9UH9ssy8EzgA+H5mHgJsBdwGnBURfx8RN1X/dgPmRMRmTfvbEXh0gGO9ktLFCMoP81dFxBTgKMoVvY0H2E6rt7nA14FDKFVfl1Iael9rON8+W617HvCx6irFuZRGV6OvAQdW+5q7iuLrN2GGn6mru1adl6+klKg3msUACV2/89c8mfkjoLEh1FFVFQI8C/R9l3Y2nKs3RcRuETGGUoHw5urfDhFxWMO+DgVGV9U0/wysx6rR+Dl6HHB+ZiYwvyrP1zDXRuflK2lKLlRmsWwXxj4AXFglf39DSVassax4GJ7OA86IiBupGncR8VZK4+7CiFgHOAU4i1ImucIiYiPKHziUD/f1q8ZdB/DmiNg+M7tW5hhafWTm9IjYEPg45Ycq1eNXA+dVYzfcD7w2M39IqeABICK+RUlIfAB4J+VH9RuAic3HqUp+PwVcXiUr9gRenZmLquXnARPov0uHVm+/B7qqHyi/j4gnKfeTPiUzpzSt+4rMvLt6/EvgK30LImJL4Jmqyw8RMY1VY6CE2drArhFxat/Vaa1WWnVePkT5/L2jYd6ACV2/80UZ76PPhsCc6vGL4yz1qbrs3NJ3BTcifkW5itxnF8rFBjLz4YhornRcUa+kXD1+GaUSZ4so40RtTOm2eesqOo7aR6vOy4eBV/Uzf0cGrjZ7JfBIVVnxXuCPVbe3Tsr5ecVSjrdas+JhGMrM6ZQ/uubG3bHV8vnA/cD8VXC4U4ArImIUpWRpn8wcV129/gqlZF5qdCGlQfWDavp44G0RcVf1I3kCJWmwhMycRPki+AUl2bALZQCfnapV+rLaN1TrdAEXUMY8+VFf0qFyHvCRqpRda5Z/pIz/0VciuRHw5wHW/VNEvL56vB+lcdjnSWDjiNi8mn7jygY2QMJsj+oz9S2UgVgnrOxx1JZadV5+C/hqRGwUEftFxJWUixLfGmB9v/N1V9V9AcqV4V8tZd0ZwB4RMar6vt2XJc/XGcBe8OJ5v/XKBhcRL6d0M55MadRdkJkHZ+Y4yuB/Bzf8fWj10ZLzMjMfBboi4qPV+l+JiDMo5+BLuqtVF98+WC0bD/w2Mw+oPkffBGzZ8Pm+xrHiYfi6EDgD2LaaPh44NyI+QulP/ziD93GfEBEHNkzvX/0/NSIWASMp/fM/BbwduCMzG0ff/h5wT0ScVo03IZGZF1ASAn3Tf6JUMCzLtpNoqFKossW7V8vWHmCz5jJkMvM2FicstGa5ALgoIn5NGefmHxl4QKcPAt+qfpgspJREApCZCyPiWOC6iOhmyZLPgfxzRBxXPX42Mw+gSphRrtasBVxfxfhJ+k+YfT8izmkoKdXqoSXnZWZeHRHrU/pE91LurPIMS17B8ztfjU4GzosyePnvaKhMbFZVOV5JGVtsBGUMp59QxjQhM38aEXtHxK2U6pvmcZz6c3NE9H3+XUa568tREbEnZdyTDuDYzOyuPm/f1xDP3CjjP3wQ+PLyPGm1vVael8cAp1fr91C6uP0vMKZa/pbqe34RpW39uczMKkFxftO+zqdUPayRA0129Pb620aSJGlNERFvzsxV1X1IktYo1Thi22Tm/a2OZTgx8bCai4gfU/oUNXo6M9/R3/qSpP5VV1qm9rMoM/PDQx2PBJ6XGl4i4u3ASf0sOjszB7xLgVQnz8uhYeJBkiRJkiTVxsElJUmSJElSbUw8SJIkSZKk2ph4kCRJyyUi9o+I3oh4T9P8eyPiogG26YyIo6rHF0XEuBU47k7V6OGSJGkYMfEgSZJWxAzgH/omImIMsP5S1n895TaNkiRpDTOq1QFIkqRh6R5gx4jYJDPnAO8FLgW2jYgjKCOELwJ+nZmnAp8FxkZE3/3LPxwRpwAbAydk5m0RcTJwJLAQ+GVmfjoiXl7ttwOY3XfwiPgS8BbKRZQfZOZZQ/CcJUnSCrDiQZIkragfA++KiA7gTcA0yi2cvwC8NTP3BraOiIOALwE3ZOZ3q23vyMy3AOcA768qJt4NvLn6t0NEHAacTEksHAD8pOHYxwBHAfsCz9f8PCVJ0kow8SBJklbUZZQKhX2BX1XzRgGbA5Or8Rh2Bl7dz7Z3VP/PBtYDdgJuycwFmdlb7W+X6t9t1bo3N2x/JHA6cB2wySp6PpIkqQYmHiRJ0grJzD9QxnWYCFxSze4F/hc4KDP3p1Q03Ar0sOTvjt6m3c0A9oiIUVUFxb7A76v5e1XrvBEgItYBjqCMMfEWSsXEK1fpk5MkSauMiQdJkrQyrgD+KjN/X00/DnwD+EVE3AocSkkgPAiMiYhP9LeTzJwOXEmpargNmEXpWvEvwOFV9cTbq3XnA93A3cANwFTg4RqemyRJWgU6enubLzhIkiRJkiStGlY8SJIkSZKk2ph4kCRJkiRJtTHxIEmSJEmSamPiQZIkSZIk1cbEgyRJkiRJqo2JB0mSJEmSVBsTD5IkSZIkqTYmHiRJkiRJUm3+Pz5HQLYic5KHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We give an example of test error rate.\n",
    "sim = 100\n",
    "\n",
    "mr_vsa_lda = []\n",
    "mr_f5_lda = []\n",
    "mr_f10_lda = []\n",
    "\n",
    "mr_vsa_qda = []\n",
    "mr_f5_qda = []\n",
    "mr_f10_qda = []\n",
    "\n",
    "for _ in range(sim):   \n",
    "    data_x, data_y = generate_data_ex1(sigma, sigma)\n",
    "    \n",
    "    # LDA.\n",
    "    vsa_err_lda = validation_set(0.5, data_x, data_y, random_states=1)[4]\n",
    "    k5_err_lda = k_fold(5, data_x, data_y)[4]\n",
    "    k10_err_lda = k_fold(10, data_x, data_y)[4]\n",
    "    \n",
    "            \n",
    "    mr_vsa_lda.append(vsa_err_lda.mean())\n",
    "    mr_f5_lda.append(k5_err_lda.mean())\n",
    "    mr_f10_lda.append(k10_err_lda.mean())\n",
    "    \n",
    "    #QDA.\n",
    "    vsa_err_qda = validation_set(0.5, data_x, data_y, random_states=1, \n",
    "                                 method=QuadraticDiscriminantAnalysis())[4]\n",
    "    k5_err_qda = k_fold(5, data_x, data_y,\n",
    "                       method=QuadraticDiscriminantAnalysis())[4]\n",
    "    k10_err_qda = k_fold(10, data_x, data_y,\n",
    "                        method=QuadraticDiscriminantAnalysis())[4]    \n",
    "    \n",
    "    mr_vsa_qda.append(vsa_err_qda.mean())\n",
    "    mr_f5_qda.append(k5_err_qda.mean())\n",
    "    mr_f10_qda.append(k10_err_qda.mean())\n",
    "\n",
    "mr_vsa_lda = np.array(mr_vsa_lda).reshape(-1,1)\n",
    "mr_f5_lda = np.array(mr_f5_lda).reshape(-1, 1)\n",
    "mr_f10_lda = np.array(mr_f10_lda).reshape(-1,1)\n",
    "\n",
    "mr_vsa_qda = np.array(mr_vsa_qda).reshape(-1,1)\n",
    "mr_f5_qda = np.array(mr_f5_qda).reshape(-1, 1)\n",
    "mr_f10_qda = np.array(mr_f10_qda).reshape(-1,1)\n",
    "\n",
    "mr_comb = np.concatenate((mr_vsa_lda, mr_vsa_qda, \n",
    "                          mr_f5_lda, mr_f5_qda, \n",
    "                          mr_f10_lda, mr_f10_qda), axis=1)\n",
    "\n",
    "df_comb = pd.DataFrame(mr_comb, columns=['VS_LDA', 'VS-QDA',\n",
    "                                         '5Fold_LDA', '5Fold_QDA',\n",
    "                                         '10Fold_LDA', '10Fold_QDA'])\n",
    "\n",
    "# Create the long dataframe to prepare for the plot.\n",
    "df_comb_long = pd.melt(df_comb, var_name='Methods', value_name='MSE')\n",
    "\n",
    "# Boxplot.\n",
    "fig1, ax1 = plt.subplots(figsize=(18, 3))\n",
    "\n",
    "sns.boxplot(x='Methods', y = 'MSE', data=df_comb_long, orient='v', ax=ax1)\n",
    "ax1.set_title('Comparisions In Test Errors Among Different Methods')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
